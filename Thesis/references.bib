@inproceedings{mildenhall2020nerf,
  title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
  author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
  year={2020},
  booktitle={ECCV},
}

@book{ussr1981phototech,
	title =     {Фотокинотехника. Энциклопедия},
	author =    {Иофис Е.А. (ред.)},
	publisher = {Советская Энциклопедия},
	year =      {1981},
}

@book{Hartley:2003:MVG:861369,
  address = {New York, NY, USA},
  author = {Hartley, Richard and Zisserman, Andrew},
  biburl = {https://www.bibsonomy.org/bibtex/24867b22ef159cc28fc1bbe1476a0ec57/daill},
  description = {Multiple View Geometry in Computer Vision},
  edition = 2,
  interhash = {7894893cb1baf364de16c2d27541e4c4},
  intrahash = {4867b22ef159cc28fc1bbe1476a0ec57},
  isbn = {0521540518},
  keywords = {geometry multiple view zisserman},
  publisher = {Cambridge University Press},
  title = {Multiple View Geometry in Computer Vision},
  year = 2003
}

@misc{fsian2022comparisonstereomatchingalgorithms,
	title={Comparison of Stereo Matching Algorithms for the Development of Disparity Map},
	author={Hamid Fsian and Vahid Mohammadi and Pierre Gouton and Saeid Minaei},
	year={2022},
	eprint={2210.15926},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/2210.15926},
}

@article{kok2019reviewonsterevision,
	author = {Kok, Kai Yit and Rajendran, Parvathy},
	year = {2019},
	month = {11},
	pages = {},
	title = {A Review on Stereo Vision Algorithm: Challenges and Solutions},
	volume = {13},
	doi = {10.37936/ecti-cit.2019132.194324}
}

@article{10.1109/34.273735,
	author = {Laurentini, A.},
	title = {The Visual Hull Concept for Silhouette-Based Image Understanding},
	year = {1994},
	issue_date = {February 1994},
	publisher = {IEEE Computer Society},
	address = {USA},
	volume = {16},
	number = {2},
	issn = {0162-8828},
	url = {https://doi.org/10.1109/34.273735},
	doi = {10.1109/34.273735},
	abstract = {Many algorithms for both identifying and reconstructing a 3-D object are based on the 2-D silhouettes of the object. In general, identifying a nonconvex object using a silhouette-based approach implies neglecting some features of its surface as identification clues. The same features cannot be reconstructed by volume intersection techniques using multiple silhouettes of the object. This paper addresses the problem of finding which parts of a nonconvex object are relevant for silhouette-based image understanding. For this purpose, the geometric concept of visual hull of a 3-D object is introduced. This is the closest approximation of object S that can be obtained with the volume intersection approach; it is the maximal object silhouette-equivalent to S, i.e., which can be substituted for S without affecting any silhouette. Only the parts of the surface of S that also lie on the surface of the visual hull can be reconstructed or identified using silhouette-based algorithms. The visual hull depends not only on the object but also on the region allowed to the viewpoint. Two main viewing regions result in the external and internal visual hull. In the former case the viewing region is related to the convex hull of S, in the latter it is bounded by S. The internal visual hull also admits an interpretation not related to silhouettes. Algorithms for computing visual hulls are presented and their complexity analyzed. In general, the visual hull of a 3-D planar face object turns out to be bounded by planar and curved patches.},
	journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
	month = feb,
	pages = {150–162},
	numpages = {13},
	keywords = {silhouette-based image understanding, object reconstruction, object identification, nonconvex object, internal visual hull, image reconstruction, external visual hull}
}

@inproceedings{10.5555/794189.794361,
author = {Seitz, Steven M. and Dyer, Charles R.},
title = {Photorealistic Scene Reconstruction by Voxel Coloring},
year = {1997},
isbn = {0818678224},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {A novel scene reconstruction technique is presented, different from previous approaches in its ability to cope with large changes in visibility and its modeling of intrinsic scene color and texture information. The method avoids image correspondence problems by working in a discretized scene space whose voxels are traversed in a fixed visibility ordering. This strategy takes full account of occlusions and allows the input cameras to be far apart and widely distributed about the environment. The algorithm identifies a special set of invariant voxels which together form a spatial and photometric reconstruction of the scene, fully consistent with the input images. The approach is evaluated with images from both inward- and outward-facing cameras.},
booktitle = {Proceedings of the 1997 Conference on Computer Vision and Pattern Recognition (CVPR '97)},
pages = {1067},
keywords = {image-based rendering, shape from motion, stereo, view synthesis},
series = {CVPR '97}
}

@techreport{10.5555/898435,
	author = {Kutulakos, Kiriakos N. and Seitz, Steven M.},
	title = {A Theory of Shape by Space Carving},
	year = {1998},
	publisher = {University of Rochester},
	address = {USA},
	abstract = {In this paper we consider the problem of computing the 3D shape of an unknown, arbitrarily-shaped scene from multiple color photographs taken at known but arbitrarily-distributed viewpoints. By studying the equivalence class of all 3D shapes that reproduce the input photographs, we prove the existence of a special member of this class, the maximal photo-consistent shape, that (1) can be computed from an arbitrary volume that contains the scene, and (2) subsumes all other members of this class. We then give a provably-correct algorithm, called Space Carving, for computing this shape and present experimental results from applying it to the reconstruction of geometrically-complex scenes from several photographs. The approach is specifically designed to (1) build 3D shapes that allow faithful reproduction of all input photographs, (2) resolve the complex interactions between occlusion, parallax, shading, and their effects on arbitrary collections of photographs of a scene, and (3) follow a "least commitment" approach to 3D shape recovery.}
}

@inproceedings{10.1109/CVPR.2007.383246,
	author = {Furukawa, Yasutaka and Ponce, J.},
	year = {2007},
	month = {06},
	pages = {},
	title = {Accurate, Dense, and Robust Multi-View Stereopsis},
	volume = {32},
	journal = {IEEE Trans. Pattern Anal.},
	doi = {10.1109/CVPR.2007.383246}
}

@inproceedings{10.1109/CVPR.1998.698642,
	author={Baker, S. and Szeliski, R. and Anandan, P.},
	booktitle={Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)}, 
	title={A layered approach to stereo reconstruction},
	year={1998},
	volume={},
	number={},
	pages={434-441},
	keywords={Layout;Image reconstruction;Pixel;Motion estimation;Cameras;Stereo image processing;Computer science;Read only memory;Equations;Sprites (computer)},
	doi={10.1109/CVPR.1998.698642}
}

@inproceedings{schoenberger2016mvs,
    author={Sch\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},
    title={Pixelwise View Selection for Unstructured Multi-View Stereo},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2016},
}

@article{Knapitsch2017,
    author    = {Arno Knapitsch and Jaesik Park and Qian-Yi Zhou and Vladlen Koltun},
    title     = {Tanks and Temples: Benchmarking Large-Scale Scene Reconstruction},
    journal   = {ACM Transactions on Graphics},
    volume    = {36},
    number    = {4},
    year      = {2017},
}

@book{book:869357,
   title =     {Fundamentals of Computerized Tomography: Image Reconstruction from Projections},
   author =    {Gabor T. Herman},
   publisher = {Springer},
   isbn =      {9781846287237,1846287235},
   year =      {2009},
   series =    {Advances in Pattern Recognition},
   edition =   {2nd},
   volume =    {},
}

@inproceedings{10.1145/1179849.1179918,
	author = {Trifonov, Borislav and Bradley, Derek and Heidrich, Wolfgang},
	title = {Tomographic reconstruction of transparent objects},
	year = {2006},
	isbn = {1595933646},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1179849.1179918},
	doi = {10.1145/1179849.1179918},
	booktitle = {ACM SIGGRAPH 2006 Sketches},
	pages = {55–es},
	location = {Boston, Massachusetts},
	series = {SIGGRAPH '06}
}

@article{IHRKE2006484,
	title = {Adaptive grid optical tomography},
	journal = {Graphical Models},
	volume = {68},
	number = {5},
	pages = {484-495},
	year = {2006},
	note = {Special Issue on the Vision, Video and Graphics Conference 2005},
	issn = {1524-0703},
	doi = {https://doi.org/10.1016/j.gmod.2006.08.001},
	url = {https://www.sciencedirect.com/science/article/pii/S1524070306000610},
	author = {Ivo Ihrke and Marcus Magnor},
	keywords = {Image based reconstruction, Dynamic volumetric models, Natural phenomena},
	abstract = {Image-based modeling of semi-transparent, dynamic phenomena is a challenging task. We present an optical tomography method that uses an adaptive grid for the reconstruction of a three-dimensional density function from its projections. The proposed method is applied to reconstruct thin smoke and flames volumetrically from synchronized multi-video recordings. Our adaptive reconstruction algorithm computes a time-varying volumetric model, that enables the photorealistical rendering of the recorded phenomena from arbitrary viewpoints. In contrast to previous approaches we sample the underlying unknown, three-dimensional density function adaptively which enables us to achieve a higher effective resolution of the reconstructed models.}
}

@inproceedings{10.1109/CVPR.2016.4454,
	author={Schönberger, Johannes L. and Frahm, Jan-Michael},
	booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	title={Structure-from-Motion Revisited},
	year={2016},
	volume={},
	number={},
	pages={4104-4113},
	keywords={Image reconstruction;Robustness;Cameras;Internet;Image registration;Transmission line matrix methods;Pipelines},
	doi={10.1109/CVPR.2016.445}
}

@article{10.1145/1141911.1141964,
author = {Snavely, Noah and Seitz, Steven M. and Szeliski, Richard},
title = {Photo tourism: exploring photo collections in 3D},
year = {2006},
issue_date = {July 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/1141911.1141964},
doi = {10.1145/1141911.1141964},
abstract = {We present a system for interactively browsing and exploring large unstructured collections of photographs of a scene using a novel 3D interface. Our system consists of an image-based modeling front end that automatically computes the viewpoint of each photograph as well as a sparse 3D model of the scene and image to model correspondences. Our photo explorer uses image-based rendering techniques to smoothly transition between photographs, while also enabling full 3D navigation and exploration of the set of images and world geometry, along with auxiliary information such as overhead maps. Our system also makes it easy to construct photo tours of scenic or historic locations, and to annotate image details, which are automatically transferred to other relevant images. We demonstrate our system on several large personal photo collections as well as images gathered from Internet photo sharing sites.},
journal = {ACM Trans. Graph.},
month = jul,
pages = {835–846},
numpages = {12},
keywords = {image-based modeling, image-based rendering, photo browsing, structure from motion}
}

@inbook{10.1145/3596711.3596766,
	author = {Snavely, Noah and Seitz, Steven M. and Szeliski, Richard},
	title = {Photo tourism: exploring photo collections in 3D},
	year = {2023},
	isbn = {9798400708978},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	edition = {1},
	url = {https://doi.org/10.1145/3596711.3596766},
	abstract = {We present a system for interactively browsing and exploring large unstructured collections of photographs of a scene using a novel 3D interface. Our system consists of an image-based modeling front end that automatically computes the viewpoint of each photograph as well as a sparse 3D model of the scene and image to model correspondences. Our photo explorer uses image-based rendering techniques to smoothly transition between photographs, while also enabling full 3D navigation and exploration of the set of images and world geometry, along with auxiliary information such as overhead maps. Our system also makes it easy to construct photo tours of scenic or historic locations, and to annotate image details, which are automatically transferred to other relevant images. We demonstrate our system on several large personal photo collections as well as images gathered from Internet photo sharing sites.},
	booktitle = {Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
	articleno = {54},
	numpages = {12}
}

@inproceedings{10.1109/3DV.2013.25,
	author={Wu, Changchang},
	booktitle={2013 International Conference on 3D Vision - 3DV 2013},
	title={Towards Linear-Time Incremental Structure from Motion},
	year={2013},
	volume={},
	number={},
	pages={127-134},
	keywords={Barium;Cameras;Image reconstruction;Time complexity;Three-dimensional displays;Linear systems;Optimization;VisualSFM;Structure from Motion},
	doi={10.1109/3DV.2013.25}
}

@inproceedings{10.1109/CVPR.2015.7298949,
	author={Heinly, Jared and Schönberger, Johannes L. and Dunn, Enrique and Frahm, Jan-Michael},
	booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	title={Reconstructing the World in Six Days},
	year={2015},
	volume={},
	number={},
	pages={3287-3295},
	keywords={Solid modeling;Streaming media;Visualization;Computational modeling;Registers;Image reconstruction;Scalability},
	doi={10.1109/CVPR.2015.7298949}
}

@article{Matusik2002VHull,
	author = {Matusik, Wojciech and Buehler, Chris and Mcmillan, Leonard and Gortler, Steven},
	year = {2002},
	month = {03},
	pages = {},
	title = {An Efficient Visual Hull Computation Algorithm}
}

@book{Horn1989SFS,
	author = {Horn, Berthold and Brooks, Michael},
	year = {1989},
	month = {01},
	pages = {},
	title = {Shape from Shading},
	volume = {2}
}

@article{10.1117/12.7972479,
	author = {Woodham, Robert},
	year = {1992},
	month = {01},
	pages = {},
	title = {Photometric Method for Determining Surface Orientation from Multiple Images},
	volume = {19},
	journal = {Optical Engineering},
	doi = {10.1117/12.7972479}
}

@article{McGunnigle-2012,
	doi       = {10.1364/JOSAA.29.000627},
	title     = {Photometric stereo applied to diffuse surfaces that violate Lambert’s law},
	author    = {McGunnigle, G. and Dong, Junyu and Wang, Xuefang},
	publisher = {Optical Society of America},
	journal   = {Journal of the Optical Society of America A},
	issn      = {1084-7529,1520-8532},
	year      = {2012},
	volume    = {29},
	issue     = {4},
	pages     = {627},
	url       = {http://doi.org/10.1364/JOSAA.29.000627}
}

@inproceedings{10.1109/CVPR.2010.5540082,
	author={Cui, Yan and Schuon, Sebastian and Chan, Derek and Thrun, Sebastian and Theobalt, Christian},
	booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	title={3D shape scanning with a time-of-flight camera},
	year={2010},
	volume={},
	number={},
	pages={1173-1180},
	keywords={Shape;Cameras;Sensor systems;Costs;Production;Sensor phenomena and characterization;Noise shaping;Infrared sensors;Noise level;Filtering},
	doi={10.1109/CVPR.2010.5540082}
}

@article{10.1109/34.667888,
	doi       = {10.1109/34.667888},
	title     = {Structured light using pseudorandom codes},
	author    = {Morano, R.A. and Ozturk, C. and Conn, R. and Dubin, S. and Zietz, S. and Nissano, J.},
	publisher = {IEEE},
	journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	issn      = {0162-8828,2160-9292},
	year      = {1998},
	volume    = {20},
	issue     = {3},
	pages     = {0--327},
	url       = {http://doi.org/10.1109/34.667888}
}

@book{Antipov1988,
	title =     {Радиолокационные станции с цифровым синтезированием апертуры антенны},
	author =    {},
	publisher = {Радио и связь},
	isbn =      {5-256-00019-5},
	year =      {1988},
	series =    {},
	edition =   {},
	volume =    {},
}

@inproceedings{ji2017surfacenet,
	title={SurfaceNet: An End-To-End 3D Neural Network for Multiview Stereopsis},
	author={Ji, Mengqi and Gall, Juergen and Zheng, Haitian and Liu, Yebin and Fang, Lu},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
	pages={2307--2315},
	year={2017}
}

@misc{kar2017learningmultiviewstereomachine,
	title={Learning a Multi-View Stereo Machine},
	author={Abhishek Kar and Christian Häne and Jitendra Malik},
	year={2017},
	eprint={1708.05375},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/1708.05375},
}

@misc{yao2018mvsnetdepthinferenceunstructured,
	title={MVSNet: Depth Inference for Unstructured Multi-view Stereo},
	author={Yao Yao and Zixin Luo and Shiwei Li and Tian Fang and Long Quan},
	year={2018},
	eprint={1804.02505},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/1804.02505},
}

@misc{yao2019recurrentmvsnethighresolutionmultiview,
	title={Recurrent MVSNet for High-resolution Multi-view Stereo Depth Inference},
	author={Yao Yao and Zixin Luo and Shiwei Li and Tianwei Shen and Tian Fang and Long Quan},
	year={2019},
	eprint={1902.10556},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/1902.10556},
}

@misc{gu2020cascadecostvolumehighresolution,
	title={Cascade Cost Volume for High-Resolution Multi-View Stereo and Stereo Matching},
	author={Xiaodong Gu and Zhiwen Fan and Zuozhuo Dai and Siyu Zhu and Feitong Tan and Ping Tan},
	year={2020},
	eprint={1912.06378},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/1912.06378},
}

@inproceedings{10.1109/CVPR.2017.272,
	author={Schöps, Thomas and Schönberger, Johannes L. and Galliani, Silvano and Sattler, Torsten and Schindler, Konrad and Pollefeys, Marc and Geiger, Andreas},
	booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	title={A Multi-view Stereo Benchmark with High-Resolution Images and Multi-camera Videos},
	year={2017},
	volume={},
	number={},
	pages={2538-2547},
	keywords={Benchmark testing;Cameras;Three-dimensional displays;Lasers;Image resolution;Videos;Robot vision systems},
	doi={10.1109/CVPR.2017.272}
}
